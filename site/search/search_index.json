{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"API Documentation \u2013 Nutritional Deficiency Detection Using Deep Learning","text":"<p>Welcome to the API documentation for the Nutritional Deficiency Detection project. This guide provides detailed reference material for the internal Python modules and classes used in the system, particularly focusing on data handling and preparation.</p>"},{"location":"#overview","title":"Overview","text":"<p>This project aims to detect nutritional deficiencies using a deep learning pipeline that leverages both image and tabular data.</p> <p>This documentation is divided into:</p> <ul> <li><code>custom_data_generator.py</code> \u2013 Multi-modal Keras data generator  </li> <li><code>data_manager.py</code> \u2013 Dataset preparation, mapping, and management  </li> <li>Examples \u2013 Sample usage of core components in training/evaluation</li> </ul>"},{"location":"#modules-covered","title":"Modules Covered","text":""},{"location":"#1-multimodaldatagenerator","title":"1. <code>MultiModalDataGenerator</code>","text":"<p>File: <code>custom_data_generator.py</code></p> <p>A Keras <code>Sequence</code> generator that merges image and tabular data for training multi-input models.</p> <ul> <li>Batch generation</li> <li>Augmentation support</li> <li>On-the-fly shuffling</li> <li>Feature scaling</li> </ul>"},{"location":"#2-nhanesimagemapper","title":"2. <code>NHANESImageMapper</code>","text":"<p>File: <code>data_manager.py</code></p> <p>Responsible for: - Reading tabular and image metadata - Pairing image and tabular data - Stratified train-test splitting - Normalization and data formatting</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>For installation and environment setup, refer to Getting Started.</p>"},{"location":"#examples","title":"Examples","text":"<p>See the Examples folder for:</p> <ul> <li>Initializing data generators</li> <li>Mapping and pairing NHANES datasets</li> <li>Loading images and tabular features</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>This documentation is actively being developed. If you'd like to improve or extend the docs:</p> <ol> <li>Fork the repository</li> <li>Work on the <code>docs/</code> folder</li> <li>Submit a pull request with reference to the relevant issue</li> </ol>"},{"location":"#related-links","title":"Related Links","text":"<ul> <li>Project Repository: GitHub Repo</li> <li>Issue Tracker: #12 \u2013 API Documentation</li> </ul> <p>Note: This documentation is meant for contributors and developers. If you're looking for how to use the model or retrain it, please check the usage guides in Getting Started.</p>"},{"location":"custom-data-generator/","title":"\ud83e\udde9 MultiModalDataGenerator","text":"<p>The <code>MultiModalDataGenerator</code> is a custom Keras <code>Sequence</code> class that enables training with multi-input models using both image and tabular data.</p> <p>It: - Supports batch-wise data generation - Scales tabular features - Applies optional image augmentation - Works seamlessly with Keras model training</p>"},{"location":"custom-data-generator/#constructor","title":"\ud83d\udcda Constructor","text":"<pre><code>MultiModalDataGenerator(\n    dataset,\n    batch_size=32,\n    image_size=(224, 224),\n    shuffle=True,\n    augment=False,\n    tabular_features=None,\n    num_classes=None\n)\n</code></pre>"},{"location":"custom-data-generator/#parameters","title":"Parameters","text":"Name Type Description <code>dataset</code> <code>list[dict]</code> List of samples, each with <code>'image_path'</code>, <code>'features'</code>, <code>'label'</code> <code>batch_size</code> <code>int</code> Batch size for training <code>image_size</code> <code>tuple</code> Target image resolution <code>(width, height)</code> <code>shuffle</code> <code>bool</code> Shuffle dataset at end of each epoch <code>augment</code> <code>bool</code> Apply image augmentations if True <code>tabular_features</code> <code>list[str]</code> List of tabular features to extract <code>num_classes</code> <code>int</code> Number of output classes (for one-hot encoding); optional"},{"location":"custom-data-generator/#key-methods","title":"Key Methods","text":"<p><code>__len__()</code>: Returns number of batches per epoch.</p> <p><code>__getitem__(idx)</code> : Returns a batch of image and tabular data with labels.</p> <p><code>on_epoch_end()</code> : Shuffles the dataset after each epoch if shuffle=True.</p> <p><code>init_scalers()</code> : Initializes MinMaxScaler for tabular data and fits on the full dataset.</p> <p><code>__data_generation(batch_samples)</code>  Internal method to: * Load and preprocess image * Scale tabular data * Return formatted input-output pairs</p>"},{"location":"custom-data-generator/#example-usage","title":"Example Usage","text":"<pre><code>from custom_data_generator import MultiModalDataGenerator\nfrom data_manager import NHANESImageMapper\n\n# Prepare dataset\nmapper = NHANESImageMapper(\"dataset/NHANES\", \"dataset/Image data\")\npaired_data = mapper.create_paired_dataset()\n\n# Instantiate generator\ngenerator = MultiModalDataGenerator(\n    dataset=paired_data[\"train\"],\n    batch_size=16,\n    augment=True,\n    tabular_features=[\"age\", \"bmi\", \"calcium\", \"vitamin_d\"],\n    num_classes=3\n)\n\n# Fetch a batch\n(images, tabular_inputs), labels = generator[0]\n</code></pre>"},{"location":"custom-data-generator/#output-format","title":"Output Format","text":"<p>Each batch returns:</p> <pre><code>([image_batch, tabular_batch], label_batch)\n</code></pre> <p>Compatible with Keras models that use multiple inputs.</p>"},{"location":"custom-data-generator/#notes","title":"Notes","text":"<ul> <li>Tabular features must be numerical and normalized (handled internally)</li> <li>Label encoding is one-hot by default (if <code>num_classes</code> is specified)</li> <li>Images are resized using PIL and normalized to <code>[0, 1]</code> float32 tensors</li> </ul>"},{"location":"data-manager/","title":"Data manager","text":"<p>The NHANESImageMapper class handles the pairing of tabular NHANES data with corresponding images. It prepares data for use with a multi-input deep learning pipeline.</p>"},{"location":"data-manager/#purpose","title":"Purpose","text":"<ul> <li>Load and clean NHANES tabular data</li> <li>Match records with corresponding image files using SEQN IDs</li> <li>Create training and testing datasets</li> <li>Ensure compatibility with MultiModalDataGenerator</li> </ul>"},{"location":"data-manager/#constructor","title":"Constructor","text":"<p><code>NHANESImageMapper(tabular_path, image_dir)</code></p>"},{"location":"data-manager/#parameters","title":"Parameters","text":"Name Type Description <code>tabular_path</code> <code>str</code> Path to tabular data CSV files. <code>img_dir</code> <code>str</code> Path to image directory (e.g., <code>Image data/</code>)"},{"location":"data-manager/#key-methods","title":"Key Methods","text":"<p><code>create_paired_dataset(test_size=0.2, random_state=42)</code> Pairs image paths with tabular rows and splits into train/test sets.</p> <ul> <li>Returns:</li> </ul> <pre><code>{\n    \"train\": list[dict],\n    \"test\": list[dict]\n}\n</code></pre> <p>Each <code>dict</code> contains:</p> <pre><code>{\n    \"image_path\": \"dataset/Image data/0012.jpg\",\n    \"features\": { \"age\": 23, \"bmi\": 18.5, ... },\n    \"label\": \"mild\"\n}\n</code></pre> <p><code>_preprocess_tabular_data(df)</code> * Internal method * Cleans, selects, and standardizes the tabular features * Drops rows with missing or unmatchable values</p> <p><code>_pair_data(tabular_df)</code> * Internal method * Links each row of tabular data with its image (if the image exists) * Returns a list of paired samples</p>"},{"location":"data-manager/#expected-file-structure","title":"Expected File Structure","text":"<pre><code>dataset/\n\u251c\u2500\u2500 NHANES/\n\u2502   \u2514\u2500\u2500 merged_data.csv         \u2190 Tabular data\n\u2514\u2500\u2500 Image data/\n    \u251c\u2500\u2500 train\n    \u251c\u2500\u2500 test\n    \u2514\u2500\u2500 ...\n</code></pre> <ul> <li><code>merged_data.csv</code> must include a column <code>SEQN</code> for matching</li> <li>Filenames like <code>0012.jpg</code> must match values in <code>SEQN</code> column</li> </ul>"},{"location":"data-manager/#example-usage","title":"Example Usage","text":"<pre><code>from data_manager import NHANESImageMapper\n\nmapper = NHANESImageMapper(\n    tabular_path=\"dataset/NHANES/merged_data.csv\",\n    image_dir=\"dataset/Image data/\"\n)\n\npaired_data = mapper.create_paired_dataset()\n\nprint(paired_data[\"train\"][0])\n# {\n#   \"image_path\": \"dataset/Image data/0012.jpg\",\n#   \"features\": {\"age\": 23, \"bmi\": 18.5, ...},\n#   \"label\": \"moderate\"\n# }\n</code></pre>"},{"location":"data-manager/#notes","title":"Notes","text":"<ul> <li>Handles internal cleaning of tabular data</li> <li>Ensures only valid samples with both tabular and image data are included</li> <li>Meant to be used upstream of the Keras MultiModalDataGenerator</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome! This guide will help you set up and run the Nutritional Deficiency Detection using Deep Learning project on your local machine.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python \u2265 3.8</li> <li>Git</li> <li>Virtual environment tool (optional but recommended)</li> </ul>"},{"location":"getting-started/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/25hency/Nutritional-Deficiency-Detection-using-Deep-Learning.git\ncd Nutritional-Deficiency-Detection-using-Deep-Learning\n</code></pre>"},{"location":"getting-started/#2-optional-create-a-virtual-environment","title":"2. (Optional) Create a Virtual Environment","text":"<pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#project-structure-overview","title":"Project Structure Overview","text":"<pre><code>\u251c\u2500\u2500 custom_data_generator.py      # Multi-modal Keras data generator\n\u251c\u2500\u2500 data_manager.py               # NHANES data pairing and management\n\u251c\u2500\u2500 train_multimodal.ipynb        # Training logic\n\u251c\u2500\u2500 evaluate_multimodal_model.ipynb # Model evaluation\n\u251c\u2500\u2500 dataset/                      # Folder for images and tabular CSVs\n\u2514\u2500\u2500 docs/                         # Documentation (you're here)\n</code></pre>"},{"location":"getting-started/#dataset-setup","title":"Dataset Setup","text":"<p>You need the NHANES dataset with the following structure:</p> <pre><code>dataset/\n\u251c\u2500\u2500 NHANES/                # Tabular data (.csv)\n\u2502   \u2514\u2500\u2500 merged_data.csv\n\u2514\u2500\u2500 Image data/            # Image data\n    \u251c\u2500\u2500 test.jpg\n    \u251c\u2500\u2500 train.jpg\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Make sure: * The tabular CSV contains a <code>SEQN</code> column * Image filenames match the corresponding <code>SEQN</code> (e.g., <code>0001.jpg</code> \u2194 <code>SEQN=0001</code>)</p>"},{"location":"getting-started/#running-training","title":"Running Training","text":"<p>Open and run the training notebook:</p> <pre><code>jupyter notebook train_multimodal.ipynb\n</code></pre> <p>Inside, you'll see:</p> <ul> <li>Preprocessing steps using <code>NHANESImageMapper</code></li> <li>Data loading with <code>MultiModalDataGenerator</code></li> <li>Training using a multi-input Keras model</li> </ul>"},{"location":"getting-started/#running-evaluation","title":"Running Evaluation","text":"<p>Likewise, open and run:</p> <pre><code>jupyter notebook evaluate_multimodal_model.ipynb\n</code></pre>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If images fail to load, check that filenames match the SEQN values.</li> <li>If you see missing features, check your CSV headers for typos.</li> <li>For memory errors, reduce batch size or image resolution.</li> </ul>"},{"location":"getting-started/#contributing","title":"Contributing","text":"<p>For contribution guidelines and documentation help, check the API Docs README.md.</p>"},{"location":"examples/usage-generator/","title":"\ud83e\uddea Usage Example \u2013 MultiModalDataGenerator","text":"<p>This example shows how to use the <code>MultiModalDataGenerator</code> to create training batches from paired tabular and image data.</p> <p>The generator is designed for multi-input Keras models that expect: - Preprocessed tabular features - Resized image tensors - One-hot encoded labels (if applicable)</p>"},{"location":"examples/usage-generator/#step-by-step-example","title":"\ud83d\udce6 Step-by-Step Example","text":"<pre><code>from custom_data_generator import MultiModalDataGenerator\nfrom data_manager import NHANESImageMapper\n\n# Step 1: Map and pair the dataset\nmapper = NHANESImageMapper(\n    tabular_path=\"dataset/NHANES/merged_data.csv\",\n    image_dir=\"dataset/Image data/\"\n)\npaired_data = mapper.create_paired_dataset()\n\n# Step 2: Initialize the generator\ngenerator = MultiModalDataGenerator(\n    dataset=paired_data[\"train\"],\n    batch_size=16,\n    image_size=(224, 224),\n    augment=True,\n    tabular_features=[\"age\", \"bmi\", \"vitamin_d\", \"calcium\"],\n    num_classes=3  # One-hot encoded label output\n)\n\n# Step 3: Fetch a batch\n(inputs, labels) = generator[0]\nimage_batch, tabular_batch = inputs\n\n# Step 4: Inspect shapes\nprint(\"Image batch shape:\", image_batch.shape)        # e.g., (16, 224, 224, 3)\nprint(\"Tabular batch shape:\", tabular_batch.shape)    # e.g., (16, 4)\nprint(\"Labels shape:\", labels.shape)                  # e.g., (16, 3)\n</code></pre>"},{"location":"examples/usage-generator/#generator-output-format","title":"Generator Output Format","text":"<p>Each batch returns:</p> <pre><code>([image_batch, tabular_batch], label_batch)\n</code></pre> <p>This is fully compatible with multi-input Keras models:</p> <pre><code>model.fit(generator, epochs=10)\n</code></pre>"},{"location":"examples/usage-generator/#tips","title":"Tips","text":"<ul> <li><code>augment=True</code> applies random image transformations to boost generalization.</li> <li>Ensure <code>tabular_features</code> match those used in model design and data preprocessing.</li> <li>You can also use <code>generator[\"test\"]</code> to validate during training.</li> </ul>"},{"location":"examples/usage-generator/#next-tips","title":"Next Tips","text":"<p>Build a multi-input model and start training using this generator. See your training notebook (<code>train_multimodal.ipynb</code>) for full integration.</p>"},{"location":"examples/usage-mapper/","title":"Usage Example \u2013 NHANESImageMapper","text":"<p>This example demonstrates how to use the <code>NHANESImageMapper</code> to pair tabular NHANES data with their corresponding image files.</p> <p>The output is a dictionary containing training and testing data, each as a list of paired samples.</p>"},{"location":"examples/usage-mapper/#prerequisites","title":"Prerequisites","text":"<p>Make sure your project directory looks like this:</p> <pre><code>dataset/\n\u251c\u2500\u2500 NHANES/\n\u2502 \u2514\u2500\u2500 merged_data.csv # Tabular data file\n\u2514\u2500\u2500 Image data/\n\u251c\u2500\u2500 train\n\u251c\u2500\u2500 test\n\u2514\u2500\u2500 ...\n</code></pre> <p>The <code>merged_data.csv</code> file should contain a <code>SEQN</code> column whose values match the image filenames (without extension).</p>"},{"location":"examples/usage-mapper/#step-by-step-example","title":"Step-by-Step Example","text":"<pre><code>from data_manager import NHANESImageMapper\n\n# Step 1: Instantiate the Mapper\nmapper = NHANESImageMapper(\n    tabular_path=\"dataset/NHANES/merged_data.csv\",\n    image_dir=\"dataset/Image data/\"\n)\n\n# Step 2: Create Paired Dataset\npaired_data = mapper.create_paired_dataset(test_size=0.2, random_state=42)\n\n# Step 3: Inspect Output\nprint(\"Train size:\", len(paired_data[\"train\"]))\nprint(\"Test size:\", len(paired_data[\"test\"]))\n\n# Sample structure of one paired entry\nprint(paired_data[\"train\"][0])\n# {\n#   \"image_path\": \"dataset/Image data/0012.jpg\",\n#   \"features\": {\n#       \"age\": 25,\n#       \"bmi\": 18.5,\n#       ...\n#   },\n#   \"label\": \"mild\"\n# }\n</code></pre>"},{"location":"examples/usage-mapper/#notes","title":"Notes","text":"<ul> <li>Samples missing images or essential tabular values are automatically dropped.</li> <li>The <code>features</code> dictionary contains only the selected numerical columns.</li> <li>The <code>label</code> field should match the classification target (e.g., mild, moderate, severe).</li> </ul>"},{"location":"examples/usage-mapper/#next-step","title":"Next Step","text":"<p>Feed the paired data into the MultiModalDataGenerator to begin training your deep learning model.</p>"}]}